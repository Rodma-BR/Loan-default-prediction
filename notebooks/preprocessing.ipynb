{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Loan Default Prediction (Preprocessing)](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Loan Default Prediction (Preprocessing)](#toc1_)    \n",
    "  - [Libraries](#toc1_1_)    \n",
    "  - [Read](#toc1_2_)    \n",
    "  - [Preprocessing](#toc1_3_)    \n",
    "    - [Split dataset](#toc1_3_1_)    \n",
    "    - [Feature selection](#toc1_3_2_)    \n",
    "      - [Unwanted features](#toc1_3_2_1_)    \n",
    "      - [Null rates](#toc1_3_2_2_)    \n",
    "      - [Duplicates features](#toc1_3_2_3_)    \n",
    "      - [Constant and Quasi-constant features](#toc1_3_2_4_)    \n",
    "      - [Correlated features](#toc1_3_2_5_)    \n",
    "    - [Transform](#toc1_3_3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Libraries](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic python\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# Data manipulation\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing\n",
    "from feature_engine.selection import DropFeatures, DropConstantFeatures, DropDuplicateFeatures, DropCorrelatedFeatures\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "\n",
    "# appending a path\n",
    "sys.path.append('../src/')\n",
    "\n",
    "# Own modules\n",
    "import helpers as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Read](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file path\n",
    "path = \"../data/raw/\"\n",
    "raw_file = \"definitely_not_from_kaggle_loan_default_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pl.read_csv(path + raw_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 257)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>uuid</th><th>credit_application_date</th><th>default</th><th>person_bith_year_month_1_no_aggregation</th><th>activity_date_36_month_1_no_aggregation</th><th>location_cluster_03_month_1_most_frequent</th><th>contract_type_1_month_1_no_aggregation</th><th>activity_pattern_35_month_1_no_aggregation</th><th>activity_pattern_34_month_12_no_aggregation</th><th>activity_pattern_17_month_12_no_aggregation</th><th>activity_pattern_02_month_12_no_aggregation</th><th>device_age_2_month_1_social_mean</th><th>activity_pattern_09_last_12_months_max</th><th>client_type_1_month_9_no_aggregation</th><th>activity_pattern_07_last_9_months_max</th><th>activity_pattern_07_last_12_months_max</th><th>line_balance_type_11_last_12_months_max</th><th>line_balance_type_09_last_9_months_mean</th><th>activity_pattern_21_weekend_month_12_no_aggregation</th><th>activity_pattern_09_last_6_months_max</th><th>activity_pattern_09_last_9_months_max</th><th>line_balance_type_09_last_12_months_mean</th><th>activity_pattern_17_month_9_no_aggregation</th><th>line_balance_type_01_last_3_months_min</th><th>plan_data_month_12_no_aggregation</th><th>activity_pattern_25_last_12_months_min</th><th>data_usage_pattern_fortnight_1_last_12_months_max</th><th>location_work_null_month_9_no_aggregation</th><th>line_balance_type_01_last_6_months_min</th><th>activity_pattern_21_weekdaynight_month_12_no_aggregation</th><th>activity_pattern_03_weekend_month_6_no_aggregation</th><th>activity_pattern_25_last_9_months_min</th><th>mobility_pattern_03_last_3_months_mean</th><th>data_usage_pattern_days_last_6_months_min</th><th>activity_pattern_02_month_1_no_aggregation</th><th>activity_pattern_02_last_12_months_mean</th><th>billing_pattern_03_last_12_months_mean</th><th>&hellip;</th><th>activity_pattern_14_last_12_months_mean</th><th>activity_pattern_12_last_12_months_mean</th><th>activity_pattern_05_weekdaylight_last_3_months_mean</th><th>activity_pattern_14_last_9_months_mean</th><th>device_age_3_month_12_no_aggregation</th><th>credit_default_home_last_12_months_min</th><th>activity_pattern_14_last_6_months_max</th><th>device_technology_2_month_1_no_aggregation</th><th>activity_pattern_11_month_12_no_aggregation</th><th>device_count_1_month_1_no_aggregation</th><th>activity_pattern_27_last_9_months_mean</th><th>activity_pattern_21_weekdaynight_last_12_months_max</th><th>data_usage_pattern_time_8_month_1_social_min</th><th>line_balance_type_04_last_6_months_max</th><th>mobility_pattern_05_month_6_no_aggregation</th><th>data_usage_pattern_time_5_month_1_social_mean</th><th>data_usage_pattern_week_1_last_9_months_mean</th><th>location_cluster_02_month_9_no_aggregation</th><th>credit_default_work_last_6_months_mean</th><th>line_balance_type_07_last_9_months_min</th><th>data_usage_pattern_fortnight_1_last_9_months_mean</th><th>activity_pattern_11_last_9_months_max</th><th>activity_pattern_10_month_6_no_aggregation</th><th>activity_pattern_10_month_9_no_aggregation</th><th>line_months_active_2_last_12_months_mean</th><th>data_usage_pattern_days_last_3_months_mean</th><th>activity_pattern_10_weekend_last_3_months_mean</th><th>data_usage_pattern_fortnight_4_last_6_months_max</th><th>activity_pattern_11_weekdaylight_month_1_no_aggregation</th><th>activity_pattern_21_weekdaylight_last_12_months_max</th><th>location_cluster_02_month_1_no_aggregation</th><th>activity_pattern_22_weekend_last_3_months_min</th><th>mobility_pattern_05_last_6_months_min</th><th>activity_pattern_08_last_9_months_min</th><th>activity_pattern_28_last_3_months_mean</th><th>device_age_2_month_6_no_aggregation</th><th>activity_pattern_11_weekdaynight_month_9_no_aggregation</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;ab5191f0-5bf7-48d7-b52b-046316…</td><td>&quot;2022-04-29&quot;</td><td>1.0</td><td>1999.0</td><td>&quot;2019-03-01&quot;</td><td>&quot;REGION_5&quot;</td><td>&quot;TYPE_2&quot;</td><td>-184.249</td><td>22.0</td><td>-224.048</td><td>-27.9704</td><td>-104.1362</td><td>-180.4017</td><td>12.7514</td><td>234.0074</td><td>-414.8524</td><td>null</td><td>null</td><td>-198.5122</td><td>-14.5693</td><td>254.6177</td><td>null</td><td>130.2402</td><td>null</td><td>-172.1113</td><td>-67.5607</td><td>24.5808</td><td>28.0</td><td>null</td><td>-270.9978</td><td>-361.9366</td><td>116.7504</td><td>-55.6501</td><td>154.7281</td><td>312.7052</td><td>-64.8508</td><td>151.8844</td><td>&hellip;</td><td>-134.2671</td><td>177.1795</td><td>244.5875</td><td>3.7521</td><td>null</td><td>-5.4105</td><td>-151.4378</td><td>94.8894</td><td>-303.3621</td><td>-15.1243</td><td>-99.0</td><td>348.433</td><td>-91.2841</td><td>null</td><td>-252.5821</td><td>-35.0847</td><td>415.4933</td><td>1140.2032</td><td>93.1231</td><td>null</td><td>-299.9051</td><td>309.5891</td><td>-411.5654</td><td>-115.208</td><td>89.8558</td><td>-382.5563</td><td>-281.5171</td><td>-115.3785</td><td>150.4016</td><td>-250.0021</td><td>-727.2061</td><td>-410.8231</td><td>-107.3805</td><td>85.0</td><td>-19.0</td><td>-2.7676</td><td>207.0453</td></tr><tr><td>&quot;a6ca05d3-46bc-4f6f-b9ce-859bd8…</td><td>&quot;2022-09-18&quot;</td><td>0.0</td><td>null</td><td>&quot;2022-06-01&quot;</td><td>&quot;REGION_9&quot;</td><td>&quot;TYPE_1&quot;</td><td>-97.6418</td><td>null</td><td>null</td><td>null</td><td>-104.1362</td><td>-122.9593</td><td>null</td><td>165.5254</td><td>-242.0035</td><td>-152.981</td><td>79.5193</td><td>null</td><td>-12.7917</td><td>147.5048</td><td>-49.3755</td><td>null</td><td>54.7895</td><td>null</td><td>-64.4724</td><td>-20.0928</td><td>28.0</td><td>-91.2749</td><td>null</td><td>null</td><td>116.7504</td><td>-20.4386</td><td>43.1595</td><td>376.2327</td><td>-66.4822</td><td>null</td><td>&hellip;</td><td>-249.3615</td><td>153.3413</td><td>277.7486</td><td>-18.7436</td><td>null</td><td>-6.9201</td><td>-243.3904</td><td>94.8894</td><td>null</td><td>-15.1243</td><td>235.6217</td><td>348.433</td><td>86.7872</td><td>-55.3207</td><td>null</td><td>-35.8014</td><td>237.6507</td><td>null</td><td>88.1478</td><td>89.2065</td><td>-152.8886</td><td>216.2241</td><td>null</td><td>null</td><td>82.395</td><td>-156.8481</td><td>41.0</td><td>-161.5483</td><td>-27.0</td><td>-233.5792</td><td>-151.6538</td><td>-84.0</td><td>-131.669</td><td>23.3078</td><td>409.0962</td><td>null</td><td>null</td></tr><tr><td>&quot;449d78b7-6cc0-405a-8689-092ad2…</td><td>&quot;2022-11-19&quot;</td><td>null</td><td>null</td><td>&quot;2019-12-01&quot;</td><td>&quot;REGION_8&quot;</td><td>null</td><td>-179.1545</td><td>22.0</td><td>-104.4598</td><td>24.0</td><td>-103.7082</td><td>-22.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-107.0657</td><td>-8.0</td><td>-44.0</td><td>null</td><td>54.9648</td><td>null</td><td>null</td><td>22.0</td><td>null</td><td>29.5569</td><td>null</td><td>-235.6167</td><td>-245.4993</td><td>14.0</td><td>null</td><td>null</td><td>82.0</td><td>-57.0</td><td>null</td><td>&hellip;</td><td>-351.1757</td><td>-91.0</td><td>85.0</td><td>-48.397</td><td>null</td><td>null</td><td>-453.5678</td><td>null</td><td>-137.2204</td><td>null</td><td>-99.0</td><td>309.183</td><td>-76.7943</td><td>null</td><td>null</td><td>-34.9055</td><td>null</td><td>3801.252</td><td>null</td><td>null</td><td>null</td><td>262.9066</td><td>-278.7641</td><td>-95.1248</td><td>null</td><td>null</td><td>-142.2483</td><td>null</td><td>-27.0</td><td>-198.9087</td><td>-2233.5344</td><td>-84.0</td><td>null</td><td>-19.2893</td><td>null</td><td>null</td><td>186.0418</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 257)\n",
       "┌────────────┬───────────┬─────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ uuid       ┆ credit_ap ┆ default ┆ person_bi ┆ … ┆ activity_ ┆ activity_ ┆ device_ag ┆ activity_ │\n",
       "│ ---        ┆ plication ┆ ---     ┆ th_year_m ┆   ┆ pattern_0 ┆ pattern_2 ┆ e_2_month ┆ pattern_1 │\n",
       "│ str        ┆ _date     ┆ f64     ┆ onth_1_no ┆   ┆ 8_last_9_ ┆ 8_last_3_ ┆ _6_no_agg ┆ 1_weekday │\n",
       "│            ┆ ---       ┆         ┆ _ag…      ┆   ┆ mon…      ┆ mon…      ┆ reg…      ┆ nig…      │\n",
       "│            ┆ str       ┆         ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│            ┆           ┆         ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞════════════╪═══════════╪═════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ ab5191f0-5 ┆ 2022-04-2 ┆ 1.0     ┆ 1999.0    ┆ … ┆ 85.0      ┆ -19.0     ┆ -2.7676   ┆ 207.0453  │\n",
       "│ bf7-48d7-b ┆ 9         ┆         ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 52b-046316 ┆           ┆         ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆           ┆         ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ a6ca05d3-4 ┆ 2022-09-1 ┆ 0.0     ┆ null      ┆ … ┆ 23.3078   ┆ 409.0962  ┆ null      ┆ null      │\n",
       "│ 6bc-4f6f-b ┆ 8         ┆         ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 9ce-859bd8 ┆           ┆         ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆           ┆         ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 449d78b7-6 ┆ 2022-11-1 ┆ null    ┆ null      ┆ … ┆ -19.2893  ┆ null      ┆ null      ┆ 186.0418  │\n",
       "│ cc0-405a-8 ┆ 9         ┆         ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 689-092ad2 ┆           ┆         ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆           ┆         ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "└────────────┴───────────┴─────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Preprocessing](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_1_'></a>[Split dataset](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all rows from the set containing training samples. We'll train and validate our model with this data\n",
    "target = \"default\"\n",
    "known_set = df.filter(pl.col(target).is_not_null())\n",
    "\n",
    "# As the dataset will be splitted in function of time i'm forced to change the schema\n",
    "known_set = known_set.with_columns(pl.col(\"credit_application_date\").cast(pl.Date()))\n",
    "\n",
    "# As there are records with almost every value being null i will handle separatedly those clients.\n",
    "# Null set must be revisited. Separate if more than 80% of values per client are null\n",
    "alpha = 0.8\n",
    "null_set = known_set.filter(pl.sum_horizontal(pl.all().is_null()) >= alpha* len(df.columns))\n",
    "known_set = known_set.filter(pl.sum_horizontal(pl.all().is_null()) < alpha* len(df.columns))\n",
    "\n",
    "# # Save both sets\n",
    "# null_set.write_csv(\"../data/raw/null_set.csv\")\n",
    "# known_set.write_csv(\"../data/raw/not_null.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 months for train and 4 months for validation\n",
    "train = known_set.filter(pl.col(\"credit_application_date\")<dt.datetime(2022,7,1))\n",
    "test = known_set.filter(pl.col(\"credit_application_date\")>=dt.datetime(2022,7,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18348, 11923, 6425)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_set.shape[0], train.shape[0], test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(shape: (2, 2)\n",
       " ┌─────────┬────────────┐\n",
       " │ default ┆ proportion │\n",
       " │ ---     ┆ ---        │\n",
       " │ f64     ┆ f64        │\n",
       " ╞═════════╪════════════╡\n",
       " │ 1.0     ┆ 0.160278   │\n",
       " │ 0.0     ┆ 0.839722   │\n",
       " └─────────┴────────────┘,\n",
       " shape: (2, 2)\n",
       " ┌─────────┬────────────┐\n",
       " │ default ┆ proportion │\n",
       " │ ---     ┆ ---        │\n",
       " │ f64     ┆ f64        │\n",
       " ╞═════════╪════════════╡\n",
       " │ 0.0     ┆ 0.80965    │\n",
       " │ 1.0     ┆ 0.19035    │\n",
       " └─────────┴────────────┘)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that default rates is similar between datasets\n",
    "train[\"default\"].value_counts(normalize=True), test[\"default\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test sets separating target feature. Transform to pandas for sklearn compatibility\n",
    "X_train = train.drop(pl.col(\"default\")).to_pandas()\n",
    "y_train = train.select(target).to_pandas()\n",
    "X_test = test.drop(pl.col(\"default\")).to_pandas()\n",
    "y_test = test.select(target).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_2_'></a>[Feature selection](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_3_2_1_'></a>[Unwanted features](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop uuid cause is unique and credit_applicatio_date to remove time dependency to the predictions\n",
    "DF_unwanted = DropFeatures(features_to_drop=[\"uuid\", \"credit_application_date\"])\n",
    "# fit the transformer\n",
    "DF_unwanted.fit(X_train)\n",
    "\n",
    "X_train = DF_unwanted.transform(X_train)\n",
    "X_test = DF_unwanted.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_3_2_2_'></a>[Null rates](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features filtered with high null values rate:  114\n"
     ]
    }
   ],
   "source": [
    "# Retain just features with less than \"x (threshold)\" rate of null values.\n",
    "null_threshold = 0.20\n",
    "null_cols = [col.name for col in (train.drop(pl.col(\"default\")).null_count()/train.shape[0]).select(pl.all().sum() >= null_threshold) if col.all()]\n",
    "print(\"Total features filtered with high null values rate: \", len(null_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_nulls = DropFeatures(features_to_drop=null_cols)\n",
    "# fit the transformer\n",
    "DF_nulls.fit(X_train)\n",
    "\n",
    "X_train = DF_nulls.transform(X_train)\n",
    "X_test = DF_nulls.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_3_2_3_'></a>[Duplicates features](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features containing the same values. Corr = 1 \n",
    "DDF = DropDuplicateFeatures()\n",
    "DDF.fit(X_train)\n",
    "\n",
    "X_train =  DDF.transform(X_train)\n",
    "X_test =  DDF.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_3_2_4_'></a>[Constant and Quasi-constant features](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features with low variance \n",
    "DCF = DropConstantFeatures(tol = 0.75, missing_values= \"ignore\")\n",
    "DCF.fit(X_train)\n",
    "\n",
    "X_train = DCF.transform(X_train)\n",
    "X_test = DCF.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_3_2_5_'></a>[Correlated features](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop correlated features given a threshold. Let's set 0.8 be the limit for pearson method\n",
    "DCORR= DropCorrelatedFeatures(variables=None, method='pearson', threshold=0.8)\n",
    "DCORR.fit(X_train)\n",
    "\n",
    "X_train = DCORR.transform(X_train)\n",
    "X_test = DCORR.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_3_'></a>[Transform](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imp_mean.fit(X_train)\n",
    "\n",
    "X_train = imp_mean.transform(X_train)\n",
    "X_test= imp_mean.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute continous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2019-03-01'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [93]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m imputer \u001b[38;5;241m=\u001b[39m KNNImputer(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mimputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m X_train \u001b[38;5;241m=\u001b[39m imp_mean\u001b[38;5;241m.\u001b[39mtransform(X_train)\n\u001b[1;32m      5\u001b[0m X_test \u001b[38;5;241m=\u001b[39m imp_mean\u001b[38;5;241m.\u001b[39mtransform(X_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/impute/_knn.py:230\u001b[0m, in \u001b[0;36mKNNImputer.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    228\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 230\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mask_fit_X \u001b[38;5;241m=\u001b[39m _get_mask(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing_values)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1012\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1012\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m   1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1015\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m   1016\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_array_api.py:745\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    743\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 745\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '2019-03-01'"
     ]
    }
   ],
   "source": [
    "imputer = KNNImputer(n_neighbors=7)\n",
    "imputer.fit(X_train)\n",
    "\n",
    "X_train = imp_mean.transform(X_train)\n",
    "X_test = imp_mean.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
